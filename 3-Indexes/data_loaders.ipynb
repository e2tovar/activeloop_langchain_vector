{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.environ.get('OPENAI_API_KEY')\n",
    "os.environ['ACTIVELOOP_TOKEN'] = os.environ.get('ACTIVELOOP_TOKEN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextLoader\n",
    "Import the LangChain and necessary loaders from  langchain.document_loaders.\n",
    "\n",
    "You can use the encoding argument to change the encoding type. (For example:  encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader('my_file.txt')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## PyPDFLoader (PDF)\n",
    "The LangChain library provides two methods for loading and processing PDF files: PyPDFLoader and PDFMinerLoader. We mainly focus on the former, which is used to load PDF files into an array of documents, where each document contains the page content and metadata with the page number. First, install the package using Python Package Manager (PIP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Matriculaciones de Automóviles de turismo\\nEnero 2024\\n2024 2023 %24/23 2024 2023 %24/23\\n68.685 64.038 7,3% 68.685 64.038 7,3%\\nTop 10 Automóviles de turismo\\nEnero-Enero\\n1º TOYOTA 7.615 TOYOTA 7.615 DACIA SANDERO 2.233 DACIA SANDERO 2.233\\n2º SEAT 5.073 SEAT 5.073 TOYOTA COROLLA 2.143 TOYOTA COROLLA 2.143\\n3º KIA 4.594 KIA 4.594 MG ZS 1.626 MG ZS 1.626\\n4º HYUNDAI 4.121 HYUNDAI 4.121 SEAT LEON 1.535 SEAT LEON 1.535\\n5º PEUGEOT 3.811 PEUGEOT 3.811 TOYOTA YARIS CROSS 1.522 TOYOTA YARIS CROSS 1.522\\n6º DACIA 3.780 DACIA 3.780 SEAT ARONA 1.501 SEAT ARONA 1.501\\n7º BMW 3.593 BMW 3.593 HYUNDAI TUCSON 1.494 HYUNDAI TUCSON 1.494\\n8º VOLKSWAGEN 3.405 VOLKSWAGEN 3.405 PEUGEOT 2008 1.465 PEUGEOT 2008 1.465\\n9º MERCEDES 3.308 MERCEDES 3.308 SEAT IBIZA 1.371 SEAT IBIZA 1.371\\n10º RENAULT 2.937 RENAULT 2.937 TOYOTA RAV 4 1.241 TOYOTA RAV 4 1.241\\nAutomóviles de turismo: Detalle por carburante (Cuota)\\nEne.      Feb. Mar.     Abr. May.     Jun. Jul.       Ago. Sep.     Oct.      Nov. Dic.     Año\\nGasolina 34,9%                            34,9%\\nDiesel 11,0%                            11,0%\\nResto* 54,1%                            54,1%\\n(*) Incluye: eléctrico puro (BEV), eléctrico de autonomía extendida (EREV), híbrido enchufable (PHEV) y no enchufable (HEV), hidrógeno (FCEV), GNC, GNL y GLP\\nAutomóviles de turismos: Detalle por segmentos\\nUnidades Cuota %24/23 Unidades Cuota %24/23\\nUrbano 2.228 3,2% -8,4% 2.228 3,2% -8,4%\\nUtilitario 11.225 16,3% 3,3% 11.225 16,3% 3,3%\\nCompacto 11.925 17,4% 13,9% 11.925 17,4% 13,9%\\nMedio 2.598 3,8% 47,8% 2.598 3,8% 47,8%\\nDeportivo 239 0,3% 64,8% 239 0,3% 64,8%\\nGrande 291 0,4% 28,8% 291 0,4% 28,8%\\nPremium 126 0,2% -13,1% 126 0,2% -13,1%\\nMonovol. Pequeño 395 0,6% 41,6% 395 0,6% 41,6%\\nMonovol. Grande 149 0,2% 9,6% 149 0,2% 9,6%\\nSUV Pequeño 13.468 19,6% 4,6% 13.468 19,6% 4,6%\\nSUV Medio 20.926 30,5% 3,0% 20.926 30,5% 3,0%\\nSUV Grande 3.494 5,1% 17,3% 3.494 5,1% 17,3%\\nSUV Premium 1.216 1,8% 21,8% 1.216 1,8% 21,8%\\nTodoterreno 405 0,6% -3,6% 405 0,6% -3,6%\\nFuente: Elaboracón (Instituto de Estudios de Automoción) en base a datos de DGT Página 1 de 2Enero Enero-EneroEnero Enero-Enero\\nAutomóviles de turismo\\nTop Marcas Top Modelos\\nEnero Enero-Enero Enero' metadata={'source': 'example_data/Informe-Turismos-Enero-2024.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"example_data/Informe-Turismos-Enero-2024.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "print(pages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field, validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpt-3.5-turbo-instruct'\n",
    "temperature = 0.0\n",
    "model = OpenAI(model_name=model_name, temperature=temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Turismo(anio_actual=2024, valor_actual=68, anio_pasado=2023, valor_pasado=64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "# Define your desired data structure.\n",
    "class Turismo(BaseModel):\n",
    "    anio_actual: int = Field(description=\"Año actual\")\n",
    "    valor_actual: int = Field(description=\"Número de ventas del año actual\")\n",
    "    anio_pasado: int = Field(description=\"Año anterior al actual\")\n",
    "    valor_pasado: int = Field(description=\"Número de ventas del año anterior\")\n",
    "\n",
    "    # You can add custom validation logic easily with Pydantic.\n",
    "    @validator('anio_actual')\n",
    "    def anio_is_actual(cls, field):\n",
    "        if field != datetime.now().year:\n",
    "            raise ValueError(\"No es el año actual\")\n",
    "        return field\n",
    "    \n",
    "    \"\"\"\n",
    "    # You can add custom validation logic easily with Pydantic.\n",
    "    @validator('valor_actual')\n",
    "    def anio_is_actual(cls, field):\n",
    "        if field < 1000:\n",
    "            raise ValueError(\"El valor es muy pequeño. Revisar formato\")\n",
    "        return field\n",
    "    \"\"\"\n",
    "    \n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=Turismo)\n",
    "    \n",
    "template = \"\"\"\n",
    "        Te daré una página de documento acerca de ventas de turismos(automóviles). \n",
    "        Necesito que extraigas de dicho texto el número total de ventas del mes en cuestion para el año actual y el pasado.\n",
    "        \n",
    "        texto: {texto}\n",
    "        \\n{format_instructions}\"\"\"\n",
    "\n",
    "template_bk = \"\"\"\n",
    "        Te daré una página de documento acerca de ventas de turismos(automóviles). \n",
    "        Necesito que extraigas de dicho texto el número total de ventas del mes en cuestion para el año actual y el pasado.\n",
    "        \n",
    "        Formato: El número suele venir como un entero formateado los miles con un punto.\n",
    "        Ejemplo: 58.365 sería 58365\n",
    "        texto: {texto}\n",
    "        \\n{format_instructions}\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"texto\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "_input = prompt.format_prompt(texto=pages[0])\n",
    "\n",
    "output = model.invoke(_input.to_string())\n",
    "parser.parse(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probando el fixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intentando corregir salida..llamamos con el formato correcto nuevamente\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Turismo(anio_actual=2024, valor_actual=68685, anio_pasado=2023, valor_pasado=64038)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import OutputFixingParser\n",
    "\n",
    "try:\n",
    "    ans = parser.parse(output)\n",
    "except Exception as e:\n",
    "    print('intentando corregir salida..llamamos con el formato correcto nuevamente')\n",
    "    o_parse = OutputFixingParser.from_llm(parser=parser, llm=model)\n",
    "    ans = o_parse.parse(output)\n",
    "\n",
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using PyPDFLoader offers advantages such as simple, straightforward usage and easy access to page content and metadata, like page numbers, in a structured format. However, it has disadvantages, including limited text extraction capabilities compared to PDFMinerLoader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SeleniumURLLoader (URL)\n",
    "The SeleniumURLLoader module offers a robust yet user-friendly approach for loading HTML documents from a list of URLs requiring JavaScript rendering. Here is a guide and example for using this class which starts by installing the package using the Python Package Manager (PIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Eddy.Tovar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Eddy.Tovar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='OPENASSISTANT TAKES ON CHATGPT!\\n\\nBuscar\\n\\nInformación\\n\\nCompras\\n\\nVer más tarde\\n\\nCompartir\\n\\nCopiar enlace\\n\\nActivar el sonido\\n\\n2x\\n\\nSi la reproducción no empieza en breve, prueba a reiniciar el dispositivo.\\n\\nSiguiente\\n\\nEn directoPróximamente\\n\\nVer ahora\\n\\nMachine Learning Street Talk\\n\\nSuscribirme\\n\\nSuscrito\\n\\nNo has iniciado sesión\\n\\nLos vídeos que veas podrían aparecer en el historial de reproducciones de la TV e influir en las recomendaciones. Puedes evitarlo si cancelas e inicias sesión en YouTube desde tu ordenador.\\n\\nCompartir\\n\\nSe ha producido un error al recuperar la información de uso compartido. Vuelve a intentarlo más tarde.\\n\\n2:19\\n\\n2:19 / 59:51\\n\\nVer vídeo completo\\n\\n•\\n\\nDesliza hacia abajo para ver más detalles\\n\\nNaN / NaN\\n\\nNaN / NaN\\n\\nBuscar' metadata={'source': 'https://www.youtube.com/watch?v=TFa539R09EQ&t=139s', 'title': 'OPENASSISTANT TAKES ON CHATGPT! - YouTube', 'description': 'Patreon: https://www.patreon.com/mlstDiscord: https://discord.gg/ESrGqhf5CBTwitter: https://twitter.com/MLStreetTalkIn this eye-opening interview, we dive de...', 'language': 'es-ES'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import SeleniumURLLoader\n",
    "\n",
    "urls = [\n",
    "    \"https://www.youtube.com/watch?v=TFa539R09EQ&t=139s\",\n",
    "    \"https://www.youtube.com/watch?v=6Zv6A_9urh4&t=112s\"\n",
    "]\n",
    "\n",
    "loader = SeleniumURLLoader(urls=urls)\n",
    "data = loader.load()\n",
    "\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SeleniumURLLoader class includes the following attributes:\n",
    "\n",
    "URLs (List[str]): List of URLs to load.\n",
    "continue_on_failure (bool, default=True): Continues loading other URLs on failure if True.\n",
    "browser (str, default=\"chrome\"): Browser selection, either 'Chrome' or 'Firefox'.\n",
    "executable_path (Optional[str], default=None): Browser executable path.\n",
    "headless (bool, default=True): Browser runs in headless mode if True.\n",
    "Customize these attributes during SeleniumURLLoader instance initialization, such as using Firefox instead of Chrome by setting the browser to \"firefox\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Drive loader\n",
    "The LangChain Google Drive Loader efficiently imports data from Google Drive by using the GoogleDriveLoader class. It can fetch data from a list of Google Docs document IDs or a single folder ID.\n",
    "\n",
    "Prepare necessary credentials and tokens:\n",
    "\n",
    "By default, the GoogleDriveLoader searches for the credentials.json file in ~/.credentials/credentials.json. Use the credentials_file keyword argument to modify this path.\n",
    "The token.json file follows the same principle and will be created automatically upon the loader's first use.\n",
    "To set up the credentials_file, follow these steps:\n",
    "\n",
    "Create a new Google Cloud Platform project or use an existing one by visiting the Google Cloud Console. Ensure that billing is enabled for your project.\n",
    "Enable the Google Drive API by navigating to its dashboard in the Google Cloud Console and clicking \"Enable.\"\n",
    "Create a service account by going to the Service Accounts page in the Google Cloud Console. Follow the prompts to set up a new service account.\n",
    "Assign necessary roles to the service account, such as \"Google Drive API - Drive File Access\" and \"Google Drive API - Drive Metadata Read/Write Access,\" depending on your needs.\n",
    "After creating the service account, access the \"Actions\" menu next to it, select \"Manage keys,\" click \"Add Key,\" and choose \"JSON\" as the key type. This generates a JSON key file and downloads it to your computer, which serves as your credentials_file.\n",
    "Retrieve the folder or document ID from the URL:\n",
    "\n",
    "Folder: https://drive.google.com/drive/u/0/folders/{folder_id}\n",
    "Document: https://docs.google.com/document/d/{document_id}/edit\n",
    "Import the GoogleDriveLoader class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import GoogleDriveLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = GoogleDriveLoader(\n",
    "    folder_id=\"your_folder_id\",\n",
    "    recursive=False  # Optional: Fetch files from subfolders recursively. Defaults to False.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "You must run `pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib` to use the Google Drive loader.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Eddy.Tovar\\Documents\\Datos\\work\\PycharmProjects\\proyectos_personales\\cursos_llm\\activeloop_langchain_vector\\venv\\lib\\site-packages\\langchain_community\\document_loaders\\googledrive.py:112\u001b[0m, in \u001b[0;36mGoogleDriveLoader._load_credentials\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moauth2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcredentials\u001b[39;00m \u001b[39mimport\u001b[39;00m Credentials\n\u001b[1;32m--> 112\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle_auth_oauthlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mflow\u001b[39;00m \u001b[39mimport\u001b[39;00m InstalledAppFlow\n\u001b[0;32m    113\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google_auth_oauthlib'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Eddy.Tovar\\Documents\\Datos\\work\\PycharmProjects\\proyectos_personales\\cursos_llm\\activeloop_langchain_vector\\3-Indexes\\data_loaders.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Eddy.Tovar/Documents/Datos/work/PycharmProjects/proyectos_personales/cursos_llm/activeloop_langchain_vector/3-Indexes/data_loaders.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m docs \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39;49mload()\n",
      "File \u001b[1;32mc:\\Users\\Eddy.Tovar\\Documents\\Datos\\work\\PycharmProjects\\proyectos_personales\\cursos_llm\\activeloop_langchain_vector\\venv\\lib\\site-packages\\langchain_community\\document_loaders\\googledrive.py:354\u001b[0m, in \u001b[0;36mGoogleDriveLoader.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load documents.\"\"\"\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfolder_id:\n\u001b[1;32m--> 354\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_documents_from_folder(\n\u001b[0;32m    355\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfolder_id, file_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfile_types\n\u001b[0;32m    356\u001b[0m     )\n\u001b[0;32m    357\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdocument_ids:\n\u001b[0;32m    358\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_documents_from_ids()\n",
      "File \u001b[1;32mc:\\Users\\Eddy.Tovar\\Documents\\Datos\\work\\PycharmProjects\\proyectos_personales\\cursos_llm\\activeloop_langchain_vector\\venv\\lib\\site-packages\\langchain_community\\document_loaders\\googledrive.py:237\u001b[0m, in \u001b[0;36mGoogleDriveLoader._load_documents_from_folder\u001b[1;34m(self, folder_id, file_types)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load documents from a folder.\"\"\"\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogleapiclient\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdiscovery\u001b[39;00m \u001b[39mimport\u001b[39;00m build\n\u001b[1;32m--> 237\u001b[0m creds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_credentials()\n\u001b[0;32m    238\u001b[0m service \u001b[39m=\u001b[39m build(\u001b[39m\"\u001b[39m\u001b[39mdrive\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mv3\u001b[39m\u001b[39m\"\u001b[39m, credentials\u001b[39m=\u001b[39mcreds)\n\u001b[0;32m    239\u001b[0m files \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fetch_files_recursive(service, folder_id)\n",
      "File \u001b[1;32mc:\\Users\\Eddy.Tovar\\Documents\\Datos\\work\\PycharmProjects\\proyectos_personales\\cursos_llm\\activeloop_langchain_vector\\venv\\lib\\site-packages\\langchain_community\\document_loaders\\googledrive.py:114\u001b[0m, in \u001b[0;36mGoogleDriveLoader._load_credentials\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle_auth_oauthlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mflow\u001b[39;00m \u001b[39mimport\u001b[39;00m InstalledAppFlow\n\u001b[0;32m    113\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m    115\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou must run \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    116\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`pip install --upgrade \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    117\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mgoogle-api-python-client google-auth-httplib2 \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    118\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mgoogle-auth-oauthlib` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    119\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mto use the Google Drive loader.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m     )\n\u001b[0;32m    122\u001b[0m creds \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mservice_account_key\u001b[39m.\u001b[39mexists():\n",
      "\u001b[1;31mImportError\u001b[0m: You must run `pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib` to use the Google Drive loader."
     ]
    }
   ],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
