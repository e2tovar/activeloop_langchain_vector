{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.environ.get('OPENAI_API_KEY')\n",
    "os.environ['ACTIVELOOP_TOKEN'] = os.environ.get('ACTIVELOOP_TOKEN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# text to write to a local file\n",
    "# taken from https://www.theverge.com/2023/3/14/23639313/google-ai-language-model-palm-api-challenge-openai\n",
    "text = \"\"\"Google opens up its AI language model PaLM to challenge OpenAI and GPT-3\n",
    "Google is offering developers access to one of its most advanced AI language models: PaLM.\n",
    "The search giant is launching an API for PaLM alongside a number of AI enterprise tools\n",
    "it says will help businesses “generate text, images, code, videos, audio, and more from\n",
    "simple natural language prompts.”\n",
    "\n",
    "PaLM is a large language model, or LLM, similar to the GPT series created by OpenAI or\n",
    "Meta’s LLaMA family of models. Google first announced PaLM in April 2022. Like other LLMs,\n",
    "PaLM is a flexible system that can potentially carry out all sorts of text generation and\n",
    "editing tasks. You could train PaLM to be a conversational chatbot like ChatGPT, for\n",
    "example, or you could use it for tasks like summarizing text or even writing code.\n",
    "(It’s similar to features Google also announced today for its Workspace apps like Google\n",
    "Docs and Gmail.)\n",
    "\"\"\"\n",
    "\n",
    "# write text to local file\n",
    "with open(\"my_file.txt\", \"w\") as file:\n",
    "    file.write(text)\n",
    "\n",
    "# use TextLoader to load text from local file\n",
    "loader = TextLoader(\"my_file.txt\")\n",
    "docs_from_file = loader.load()\n",
    "\n",
    "print(len(docs_from_file))\n",
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "917"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_from_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we use CharacterTextSplitter to split the docs into texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 373, which is longer than the specified 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# create a text splitter\n",
    "text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "\n",
    "# split documents into chunks\n",
    "docs = text_splitter.split_documents(docs_from_file)\n",
    "\n",
    "print(len(docs))\n",
    "# 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo llevamos a embedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Deep Lake as vector Database. I could store items of diverse modalities, such as texts, images, audio, and video, along with their vector representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 2 embeddings in 1 batches of size 2:: 100%|██████████| 1/1 [00:08<00:00,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://e2tovar/langchain_course_indexers_retrievers', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype      shape     dtype  compression\n",
      "  -------    -------    -------   -------  ------- \n",
      "   text       text      (2, 1)      str     None   \n",
      " metadata     json      (2, 1)      str     None   \n",
      " embedding  embedding  (2, 1536)  float32   None   \n",
      "    id        text      (2, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0f6819f3-c698-11ee-b60b-482ae342e600',\n",
       " '0f6819f4-c698-11ee-98a7-482ae342e600']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.vectorstores import DeepLake\n",
    "\n",
    "# Before executing the following code, make sure to have your\n",
    "# Activeloop key saved in the “ACTIVELOOP_TOKEN” environment variable.\n",
    "\n",
    "# create Deep Lake dataset\n",
    "# TODO: use your organization id here. (by default, org id is your username)\n",
    "my_activeloop_org_id = \"e2tovar\"\n",
    "my_activeloop_dataset_name = \"langchain_course_indexers_retrievers\"\n",
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "db = DeepLake(dataset_path=dataset_path, embedding =embeddings)\n",
    "\n",
    "# add documents to our Deep Lake dataset\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An index is a powerful data structure that meticulously organizes and stores documents to enable efficient searching, while a retriever harnesses the index to locate and return pertinent documents in response to user queries\n",
    "\n",
    "Let's create a retriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create retriever from db\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "# create a retrieval chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "\tllm=OpenAI(model=\"gpt-3.5-turbo-instruct\"),\n",
    "\tchain_type=\"stuff\",\n",
    "\tretriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'How Google plans to challenge OpenAI?', 'result': ' Google plans to challenge OpenAI by opening up its AI language model PaLM for developers to use and offering a range of AI enterprise tools to help businesses generate text, images, code, videos, audio, and more from simple natural language prompts.'}\n"
     ]
    }
   ],
   "source": [
    "query = \"How Google plans to challenge OpenAI?\"\n",
    "response = qa_chain.invoke(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay veces que no basta con encontrar el documento entero guardado y pasarlo completamente al LLM. Aveces es mejor pasarle solamente el pedacito importante. Así que luego de pasar el primer retriever se puede pasar un \"extractor\". Este extrae lo realmente importante. Para utilizarlo necesitamos otra herramienta que combina el extractor y el retriever base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "# create GPT3 wrapper\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
    "\n",
    "# create compressor for the retriever\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "\tbase_compressor=compressor,\n",
    "\tbase_retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eddy.Tovar\\Documents\\Datos\\work\\PycharmProjects\\proyectos_personales\\cursos_llm\\activeloop_langchain_vector\\venv\\lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Eddy.Tovar\\Documents\\Datos\\work\\PycharmProjects\\proyectos_personales\\cursos_llm\\activeloop_langchain_vector\\venv\\lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google opens up its AI language model PaLM to challenge OpenAI and GPT-3\n",
      "Google is offering developers access to one of its most advanced AI language models: PaLM.\n",
      "The search giant is launching an API for PaLM alongside a number of AI enterprise tools\n"
     ]
    }
   ],
   "source": [
    "# retrieving compressed documents\n",
    "retrieved_docs = compression_retriever.get_relevant_documents(\n",
    "\t\"How Google plans to challenge OpenAI?\"\n",
    ")\n",
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
